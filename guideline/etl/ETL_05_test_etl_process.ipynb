{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL test etl process\n",
    "> when you want to get `test`(sample) data to quickly test your ETL process, or need `data from a certain point` to test your ETL process, you can check how to do it here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒŒ Get `test`(sample) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ  get `test`(sample) data `w/o config`\n",
    "> when you have created a ETL process and don't wanna set config from the scratch here is a quick way to get the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/anaconda3/envs/dataverse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/08 12:26:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/11/08 12:26:06 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[ SAMPLE MODE ]\n",
      "==================================================\n",
      "This is a quick way to get the sample data for testing or debugging w/o config.\n",
      "If you want to test the ETL pipeline with your own data, please use `run` w/ config.\n",
      "==================================================\n",
      "=> spark, data = etl_pipeline.sample()\n",
      "=> data = data.map(add awesome duck to column)\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data # : 100\n",
      "sample data :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '1aad997c-c6d6-4780-93e5-f653c4182243',\n",
       "  'name': 'test_fake_ufl',\n",
       "  'text': 'Early group family ahead movie. Reveal west us he heart board trip foot. Less else when pick compare while.\\nNew relate daughter eat idea. Road professional social trade ten.',\n",
       "  'meta': '{\"name\": \"Brendan Cunningham\", \"age\": 78, \"address\": \"76915 Tanya Gateway\\\\nNew Shelbymouth, ME 17878\", \"job\": \"Nurse, adult\"}'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataverse.etl import ETLPipeline\n",
    "\n",
    "etl_pipeline = ETLPipeline()\n",
    "spark, data = etl_pipeline.sample()\n",
    "\n",
    "# default sampling will return 100 `ufl` data\n",
    "print(f\"total data # : {data.count()}\")\n",
    "print(f\"sample data :\")\n",
    "data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when you want to increase the sample size do the following\n",
    "```python\n",
    "spark, data = etl_pipeline.sample(n=10000)\n",
    "spark, data = etl_pipeline.sample(10000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[ SAMPLE MODE ]\n",
      "==================================================\n",
      "This is a quick way to get the sample data for testing or debugging w/o config.\n",
      "If you want to test the ETL pipeline with your own data, please use `run` w/ config.\n",
      "==================================================\n",
      "=> spark, data = etl_pipeline.sample()\n",
      "=> data = data.map(add awesome duck to column)\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data # : 10000\n",
      "sample data :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'a225e2e1-4051-4d36-bf61-bb00fa36e2d2',\n",
       "  'name': 'test_fake_ufl',\n",
       "  'text': 'Couple could impact approach agency fund day clear. Wife drop surface discover project.\\nWord source reveal country. Community population method on. Kitchen standard between six enough government.',\n",
       "  'meta': '{\"name\": \"Michael Sawyer\", \"age\": 32, \"address\": \"60245 Charles Spurs Apt. 866\\\\nPort Felicia, MP 61824\", \"job\": \"Civil Service fast streamer\"}'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark, data = etl_pipeline.sample(10000)\n",
    "print(f\"total data # : {data.count()}\")\n",
    "print(f\"sample data :\")\n",
    "data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒ  get `test`(sample) data `w/ config`\n",
    "> this might took some time to get the data but you can choose your own data\n",
    "- this was also introduced in `ETL_03_create_new_etl_process.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting sample data `you want`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark:\n",
      "  appname: ETL\n",
      "  driver:\n",
      "    memory: 16g\n",
      "etl:\n",
      "- name: data_ingestion___huggingface___hf2raw\n",
      "  args:\n",
      "    name_or_path:\n",
      "    - ai2_arc\n",
      "    - ARC-Challenge\n",
      "- name: utils___sampling___random\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# load from dict\n",
    "ETL_config = OmegaConf.create({\n",
    "    'spark': {\n",
    "        'appname': 'ETL',\n",
    "        'driver': {'memory': '16g'},\n",
    "    },\n",
    "    'etl': [\n",
    "        {\n",
    "            'name': 'data_ingestion___huggingface___hf2raw',\n",
    "            'args': {'name_or_path': ['ai2_arc', 'ARC-Challenge']}\n",
    "        },\n",
    "        {'name': 'utils___sampling___random'}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(OmegaConf.to_yaml(ETL_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/08 12:26:22 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/anaconda3/envs/dataverse/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /home/vscode/.cache/dataverse/dataset/huggingface_66b1e70af513110c.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[ DEBUG MODE ]\n",
      "==================================================\n",
      "Last ETL process was assigned for [ utils ]\n",
      "Spark session will not be stopped and will be returned\n",
      "If this is not intended, please assign [ data_load ] at the end.\n",
      "==================================================\n",
      "Example:\n",
      "=> spark, data = etl_pipeline.run(config)\n",
      "=> data = data.map(add awesome duck to column)\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data # : 280\n",
      "sample data :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'Mercury_7029645',\n",
       "  'question': 'Metal atoms will most likely form ions by the',\n",
       "  'choices': Row(text=['loss of electrons.', 'loss of protons.', 'gain of electrons.', 'gain of protons.'], label=['A', 'B', 'C', 'D']),\n",
       "  'answerKey': 'A'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataverse.etl import ETLPipeline\n",
    "\n",
    "etl_pipeline = ETLPipeline()\n",
    "spark, data = etl_pipeline.run(ETL_config)\n",
    "print(f\"total data # : {data.count()}\")\n",
    "print(f\"sample data :\")\n",
    "data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒŒ Test your ETL process\n",
    "> its time to test your ETL process with the sample data. define ETL process and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/08 12:26:31 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[ SAMPLE MODE ]\n",
      "==================================================\n",
      "This is a quick way to get the sample data for testing or debugging w/o config.\n",
      "If you want to test the ETL pipeline with your own data, please use `run` w/ config.\n",
      "==================================================\n",
      "=> spark, data = etl_pipeline.sample()\n",
      "=> data = data.map(add awesome duck to column)\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data # : 100\n",
      "sample data :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'b9276a8f-3a0a-4474-9fe5-0e454b3f2449',\n",
       "  'name': 'test_fake_ufl',\n",
       "  'text': 'Year main scene husband grow carry range. Tonight himself sell since across.',\n",
       "  'meta': '{\"name\": \"Kimberly Fields\", \"age\": 41, \"address\": \"625 Cynthia Expressway Suite 971\\\\nAllisonmouth, MH 13154\", \"job\": \"Civil engineer, contracting\"}'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataverse.etl import ETLPipeline\n",
    "from dataverse.etl import register_etl\n",
    "\n",
    "etl_pipeline = ETLPipeline()\n",
    "\n",
    "# get sample data\n",
    "spark, data = etl_pipeline.sample()\n",
    "print(f\"total data # : {data.count()}\")\n",
    "print(f\"sample data :\")\n",
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_etl\n",
    "def test___your___etl_process(spark, data, *args, **kwargs):\n",
    "    # add your custom process here\n",
    "    # here we are going to simply remove 'id' key\n",
    "    data = data.map(lambda x: {k: v for k, v in x.items() if k != 'id'})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'test_fake_ufl',\n",
       "  'text': 'Year main scene husband grow carry range. Tonight himself sell since across.',\n",
       "  'meta': '{\"name\": \"Kimberly Fields\", \"age\": 41, \"address\": \"625 Cynthia Expressway Suite 971\\\\nAllisonmouth, MH 13154\", \"job\": \"Civil engineer, contracting\"}'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test right away\n",
    "# - successfully removed `id` key\n",
    "etl = test___your___etl_process\n",
    "etl()(spark, data).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'test_fake_ufl',\n",
       "  'text': 'Year main scene husband grow carry range. Tonight himself sell since across.',\n",
       "  'meta': '{\"name\": \"Kimberly Fields\", \"age\": 41, \"address\": \"625 Cynthia Expressway Suite 971\\\\nAllisonmouth, MH 13154\", \"job\": \"Civil engineer, contracting\"}'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it is registered by calling it from etl_pipeline\n",
    "# - successfully removed `id` key\n",
    "etl = etl_pipeline.get('test___your___etl_process')\n",
    "etl()(spark, data).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒŒ Experiments on the data itself\n",
    "> there is no chosen way to use this `test`(sample) data. you can do whatever you want with it. here are some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'b9276a8f-3a0a-4474-9fe5-0e454b3f2449',\n",
       "  'name': 'test_fake_ufl',\n",
       "  'text': 'Year main scene husband grow carry range. Tonight himself sell since across.',\n",
       "  'meta': '{\"name\": \"Kimberly Fields\", \"age\": 41, \"address\": \"625 Cynthia Expressway Suite 971\\\\nAllisonmouth, MH 13154\", \"job\": \"Civil engineer, contracting\"}',\n",
       "  'duck': 'is quarking (physics)'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: {**x, 'duck': 'is quarking (physics)'}).take(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
