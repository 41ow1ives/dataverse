{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Common Crawl Data\n",
    "> How to use common crawl data? There is 2 ways to achieve this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump-ID\n",
    "> common crawl dump id related to the date of the crawl. ex: 2023-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark:\n",
      "  appname: CommonCrawl\n",
      "  driver:\n",
      "    memory: 16g\n",
      "etl:\n",
      "- name: data_ingestion___common_crawl___dump2raw\n",
      "  args:\n",
      "    dump: 2023-23\n",
      "    segment_n: 1\n",
      "- name: data_ingestion___common_crawl___raw2ufl\n",
      "- name: cleaning___normalization___number\n",
      "- name: deduplication___common_crawl___exact_line\n",
      "- name: quality___language___fasttext_filter\n",
      "  args:\n",
      "    whitelist:\n",
      "    - ko\n",
      "    threshold: 0.5\n",
      "- name: data_load___huggingface___ufl2hf_obj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# load from dict\n",
    "ETL_config = OmegaConf.create({\n",
    "    'spark': {\n",
    "        'appname': 'CommonCrawl',\n",
    "        'driver': {'memory': '16g'},\n",
    "    },\n",
    "    'etl': [\n",
    "        {\n",
    "            'name': 'data_ingestion___common_crawl___dump2raw',\n",
    "            'args': {\n",
    "                'dump': \"2023-23\",\n",
    "                'segment_n': 1,\n",
    "            }\n",
    "        },\n",
    "        {'name': 'data_ingestion___common_crawl___raw2ufl'},\n",
    "        {'name': 'cleaning___normalization___number'},\n",
    "        {'name': 'deduplication___common_crawl___exact_line'},\n",
    "        {\n",
    "            'name': 'quality___language___fasttext_filter',\n",
    "            'args': {\n",
    "                'whitelist': ['ko'],\n",
    "                'threshold': 0.5,\n",
    "            }\n",
    "        },\n",
    "        {'name': 'data_load___huggingface___ufl2hf_obj'}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(OmegaConf.to_yaml(ETL_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/02 09:33:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download of https://data.commoncrawl.org/crawl-data/CC-MAIN-2023-23/wet.paths.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/llm/lib/python3.10/site-packages/dataverse/etl/data_ingestion/common_crawl.py:221: UserWarning: Swallowed error 503 Server Error: Service Unavailable for url: https://data.commoncrawl.org/crawl-data/CC-MAIN-2023-23/wet.paths.gz while downloading https://data.commoncrawl.org/crawl-data/CC-MAIN-2023-23/wet.paths.gz (1 out of 3)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://data.commoncrawl.org/crawl-data/CC-MAIN-2023-23/wet.paths.gz [200] took 22s (7.1kB/s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting download of https://data.commoncrawl.org/crawl-data/CC-MAIN-2023-23/segments/1685224650409.64/wet/CC-MAIN-20230604225057-20230605015057-00644.warc.wet.gz\n",
      "Downloaded https://data.commoncrawl.org/crawl-data/CC-MAIN-2023-23/segments/1685224650409.64/wet/CC-MAIN-20230604225057-20230605015057-00644.warc.wet.gz [200] took 7s (16403.0kB/s)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset spark/-1902204008 to /root/.cache/huggingface/datasets/spark/-1902204008/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset spark downloaded and prepared to /root/.cache/huggingface/datasets/spark/-1902204008/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'meta', 'name', 'text'],\n",
       "    num_rows: 292\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataverse.etl import ETLPipeline\n",
    "\n",
    "etl_pipeline = ETLPipeline()\n",
    "\n",
    "# raw -> hf_obj\n",
    "dataset = etl_pipeline.run(ETL_config)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '7ed7ff60791711ee892062800acfdc4f',\n",
       " 'meta': '{\"title\": \"[\\\\ud3ec\\\\ud1a0] \\\\ub098\\\\ub098, \\'\\\\ub9ac\\\\uc5bc \\\\ubc14\\\\ube44\\\\uc778\\\\ud615\\' - \\\\uc804\\\\uc790\\\\uc2e0\\\\ubb38\", \"url\": \"https://www.etnews.com/20220929000212?mc=ev_002_00003\", \"date_download\": \"2023-06-05T00:07:10Z\", \"digest\": \"sha1:5RWOEBD2HWDDE3XCZZPFIAOW3AHCKN47\", \"length\": 3179, \"nlines\": 103, \"source_domain\": \"www.etnews.com\", \"cc_segment\": \"crawl-data/CC-MAIN-2023-23/segments/1685224650409.64/wet/CC-MAIN-20230604225057-20230605015057-00644.warc.wet.gz\"}',\n",
       " 'name': 'common_crawl',\n",
       " 'text': \"allshowTV\\nETstudio\\n속보\\n경제·금융\\n전자·모빌리티\\n통신·미디어·게임\\n소재·부품\\nSW·보안\\n산업·에너지·환경\\n플랫폼·유통\\n벤처·바이오\\n정치\\n국제\\n골프\\n화제의뉴스\\n인사·부음\\n오피니언\\n특집\\n연재\\n비주얼IT\\n스페셜리포트\\n뷰포인트\\n인포그래픽\\n라이프\\n공연전시\\n생활문화\\n부가서비스\\nIT교육지원캠페인\\n콘퍼런스\\nIT 전시 컨벤션\\nET프리미엄\\n시사용어\\nPDF 서비스\\n서비스 안내\\n신문구독신청\\n온라인광고안내\\n콘텐츠구매\\n초판서비스\\n번역센터\\n회원 서비스\\n패밀리미디어\\n서울신문\\nRPM0\\nEBN 산업경제신문\\n날씨\\n[포토] 나나, '리얼 바비인형'\\n발행일 : 0000-00-00 00:00\\n00일 오전 서울 용산구 한강로 용산 아이파크몰 용산 CGV에서 넷플릭스 시리즈 '글리치' 제작발표회가 열렸다.\\n배우 나나가 제작발표회에 참석했다.\\n관련 기사\\n‘더 존’ 권유리, 매력 폭발 ‘新 예능캐’의 탄생\\n케플러와 함께하는 특별한 추억! 데뷔 첫 단독 팬미팅 '케플래닛' 개최\\n온리원오브 리에, '비커즈' MV 티저…준지 향한 '눈물' 이유는?\\n‘퍼포 장인’의 귀환…드림캐쳐, ‘비전’ 댄스 프리뷰 오픈!\\n‘컴백 임박’ 드림캐쳐, ‘반전 매력’ 끝판왕 등극\\nHYNN(박혜원), 그리고 가을…‘끝나지 않은 이야기’ 발매\\n배우 전여빈, 나나가 출연하고 노덕 감독이 연출한 '글리치'는 외계인이 보이는 지효와 외계인을 추적해온 보라가 흔적 없이 사라진 지효 남자친구의 행방을 쫓으며 ‘미확인’ 미스터리의 실체에 다가서게 되는 0차원 그 이상의 추적극으로 00월 0일 공개 예정이다.\\n전자신문인터넷 김경수 기자 (kyungsoo@etnews.com)\\n핫뉴스 in LIFE\\n싸이, SNS로 '흠뻑쇼 0000' 0개 개최 도시 힌트 공개\\n[오늘의 운세] 0000년 00월 00일 띠별 운세\\nWhat’s New in Revit 0000 웨비나\\nAI/ML 분석을 위한시민 데이터 사이언티스트(Citizen Data Scientist) 되기\\n전자신문\\n지면광고\\n행사문의\\n주소: 서울시 서초구 양재대로0길 00-00 호반파크0관 0~0층 대표번호: 00-0000-0000 구독문의: 00-0000-0000~0\\n전자신문인터넷\\n개인정보취급방침\\n고충처리\\n주소: 서울시 서초구 양재대로0길 00-00 호반파크0관 0층 대표번호: 00-000-0000 사업자번호: 000-00-00000 등록번호: 서울 아00000\\n제호: 전자신문인터넷 등록일자: 0000년 00월 00일 발행일자: 0000년 00월 00일 발행·편집인: 심규호 청소년보호책임자: 김인기\\nCopyright © Electronic Times Internet. All Rights Reserved.\\n패밀리미디어 RPM0 서울신문 EBN 산업경제신문\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WET folder\n",
    "> use pre-downloaded WET files\n",
    "\n",
    "We are going to use the cache common crawl as we just downloaded while processing dump-id ETL example right before. Time to use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataverse.utils.setting import SystemSetting\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wet_path = Path(SystemSetting().CACHE_DIR) / '.cache' / 'dataverse' / 'dataset' / 'common_crawl_2023-23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark:\n",
      "  appname: CommonCrawl\n",
      "  driver:\n",
      "    memory: 16g\n",
      "etl:\n",
      "- name: data_ingestion___common_crawl___wet2raw\n",
      "  args:\n",
      "    wet_path: /root/.cache/dataverse/dataset/common_crawl_2023-23\n",
      "- name: data_ingestion___common_crawl___raw2ufl\n",
      "- name: cleaning___normalization___number\n",
      "- name: deduplication___common_crawl___exact_line\n",
      "- name: quality___language___fasttext_filter\n",
      "  args:\n",
      "    whitelist:\n",
      "    - ko\n",
      "    threshold: 0.5\n",
      "- name: data_load___huggingface___ufl2hf_obj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# load from dict\n",
    "ETL_config = OmegaConf.create({\n",
    "    'spark': {\n",
    "        'appname': 'CommonCrawl',\n",
    "        'driver': {'memory': '16g'},\n",
    "    },\n",
    "    'etl': [\n",
    "        {\n",
    "            'name': 'data_ingestion___common_crawl___wet2raw',\n",
    "            'args': {\n",
    "                'wet_path': str(wet_path),\n",
    "            }\n",
    "        },\n",
    "        {'name': 'data_ingestion___common_crawl___raw2ufl'},\n",
    "        {'name': 'cleaning___normalization___number'},\n",
    "        {'name': 'deduplication___common_crawl___exact_line'},\n",
    "        {\n",
    "            'name': 'quality___language___fasttext_filter',\n",
    "            'args': {\n",
    "                'whitelist': ['ko'],\n",
    "                'threshold': 0.5,\n",
    "            }\n",
    "        },\n",
    "        {'name': 'data_load___huggingface___ufl2hf_obj'}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(OmegaConf.to_yaml(ETL_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset spark/-1300538864 to /root/.cache/huggingface/datasets/spark/-1300538864/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset spark downloaded and prepared to /root/.cache/huggingface/datasets/spark/-1300538864/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'meta', 'name', 'text'],\n",
       "    num_rows: 292\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataverse.etl import ETLPipeline\n",
    "\n",
    "etl_pipeline = ETLPipeline()\n",
    "\n",
    "# raw -> hf_obj\n",
    "dataset = etl_pipeline.run(ETL_config)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '006dad56791611ee872a62800acfdc4f',\n",
       " 'meta': '{\"title\": \"\\\\u0413\\\\u043e\\\\u043d\\\\u0449\\\\u0438\\\\u043a\\\\u0438 Racing Point \\\\u043e \\\\u0442\\\\u0440\\\\u0430\\\\u0441\\\\u0441\\\\u0435 \\\\u0432 \\\\u041c\\\\u043e\\\\u043d\\\\u0430\\\\u043a\\\\u043e \\\\u2014 \\\\u0410\\\\u0432\\\\u0442\\\\u043e\\\\u043c\\\\u043e\\\\u0431\\\\u0438\\\\u043b\\\\u044c\\\\u043d\\\\u044b\\\\u0439 \\\\u043f\\\\u043e\\\\u0440\\\\u0442\\\\u0430\\\\u043b\", \"url\": \"http://barclay-auto.ru/gonshhiki-racing-point-o-trasse-v-monako/\", \"date_download\": \"2023-06-05T00:19:25Z\", \"digest\": \"sha1:QHIP3XNLR4MN276MCDG5B7OYV6TGOVTW\", \"length\": 4285, \"nlines\": 42, \"source_domain\": \"barclay-auto.ru\", \"cc_segment\": \"crawl-data/CC-MAIN-2023-23/segments/1685224650409.64/wet/CC-MAIN-20230604225057-20230605015057-00644.warc.wet.gz\"}',\n",
       " 'name': 'common_crawl',\n",
       " 'text': 'Гонщики Racing Point о трассе в Монако\\nВ этот уик-энд должен был пройти седьмой этап сезона – Гран При Монако, однако из-за пандемии коронавируса гонку пришлось отменить. Тем не менее, пресс-служба Racing Point попросила Лэнса Стролла и Серхио Переса сказать несколько слов о городской трассе в Монако, по которой они успели соскучиться.\\nИсточник: www.f0news.ru\\nЛэнс Стролл: «На улицах Монако мы получаем незабываемый опыт – машина словно оживает. В отличие от других трасс, здесь нет права на ошибку. Нужно дважды подумать перед тем, как затормозить немного позже и попробовать проехать поворот на более высокой скорости. Однако на этой трассе испытываешь потрясающие эмоции.\\nМне нравится второй сектор трассы. Шпилька, тоннель, торможение перед шиканой и следующий быстрый левый поворот – просто потрясающий отрезок. Он настолько классный, насколько только может быть в Формуле 0.\\nПилотирование в Монако – яркое зрелище. Речь идёт не столько о гонках, сколько о борьбе гонщика с машиной. Из-за близости стен возникает эффект «туннельного зрения». Вы ничего не видите, кроме барьеров. Ощущение, словно больше ничего не происходит в этот момент времени».\\nСерхио Перес: «В Монако особенная трасса. На ней нужно быть максимально сосредоточенным, очень уверенным и предельно точным.\\nБольше всего мне нравится шикана Nouvelle, хотя в ней я попал в свою самую сильную аварию в Формуле 0. Тем не менее, мне очень нравится этот поворот, поскольку он очень сложный».\\n← Гоночный Porsche 000 GT0 Cup тайно засняли на «Нюрбургринге»\\nДаниэль Риккардо: Нам есть за что побороться в Монако →'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WET folder - Add MinhashLSH fuzzy deduplication\n",
    "> same but more preprocessing! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark:\n",
      "  appname: CommonCrawl\n",
      "  driver:\n",
      "    memory: 16g\n",
      "etl:\n",
      "- name: data_ingestion___common_crawl___wet2raw\n",
      "  args:\n",
      "    wet_path: /root/.cache/dataverse/dataset/common_crawl_2023-23\n",
      "- name: data_ingestion___common_crawl___raw2ufl\n",
      "- name: cleaning___normalization___number\n",
      "- name: deduplication___minhash___lsh_jaccard\n",
      "- name: deduplication___common_crawl___exact_line\n",
      "- name: quality___language___fasttext_filter\n",
      "  args:\n",
      "    whitelist:\n",
      "    - ko\n",
      "    threshold: 0.5\n",
      "- name: data_load___huggingface___ufl2hf_obj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# load from dict\n",
    "ETL_config = OmegaConf.create({\n",
    "    'spark': {\n",
    "        'appname': 'CommonCrawl',\n",
    "        'driver': {'memory': '16g'},\n",
    "    },\n",
    "    'etl': [\n",
    "        {\n",
    "            'name': 'data_ingestion___common_crawl___wet2raw',\n",
    "            'args': {\n",
    "                'wet_path': str(wet_path),\n",
    "            }\n",
    "        },\n",
    "        {'name': 'data_ingestion___common_crawl___raw2ufl'},\n",
    "        {'name': 'cleaning___normalization___number'},\n",
    "        {'name': 'deduplication___minhash___lsh_jaccard'},\n",
    "        {'name': 'deduplication___common_crawl___exact_line'},\n",
    "        {\n",
    "            'name': 'quality___language___fasttext_filter',\n",
    "            'args': {\n",
    "                'whitelist': ['ko'],\n",
    "                'threshold': 0.5,\n",
    "            }\n",
    "        },\n",
    "        {'name': 'data_load___huggingface___ufl2hf_obj'}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(OmegaConf.to_yaml(ETL_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/02 09:53:07 WARN CacheManager: Asked to cache already cached data.        \n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset spark/1061218979 to /root/.cache/huggingface/datasets/spark/1061218979/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset spark downloaded and prepared to /root/.cache/huggingface/datasets/spark/1061218979/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'meta', 'name', 'text'],\n",
       "    num_rows: 287\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataverse.etl import ETLPipeline\n",
    "\n",
    "etl_pipeline = ETLPipeline()\n",
    "\n",
    "# raw -> hf_obj\n",
    "dataset = etl_pipeline.run(ETL_config)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5c63d632791911ee8d2062800acfdc4f',\n",
       " 'meta': '{\"title\": \"Advanced Rail Concepts > Roto Gripp Bucket\", \"url\": \"http://advancedrailconcepts.com/RotoGrippBucket.aspx\", \"date_download\": \"2023-06-05T01:08:24Z\", \"digest\": \"sha1:D27CRHQDVRYISILRFFDETNGFPDZLNSMO\", \"length\": 1746, \"nlines\": 61, \"source_domain\": \"advancedrailconcepts.com\", \"cc_segment\": \"/root/.cache/dataverse/dataset/common_crawl_2023-23/CC-MAIN-20230604225057-20230605015057-00644.warc.wet.gz\"}',\n",
       " 'name': 'common_crawl',\n",
       " 'text': 'Home Rail X Roto Gripp Bucket Options Surplus Awards About Us Contact Us\\nRail X\\nRoto Gripp Bucket\\nSurplus\\nSunday , June , 00 , 0000\\nThe One Bucket... that SHOUTS Mobility & Versatility...\\n\"So when you want to get a grip... Get the Roto GrippTM\"\\nThis Unique Tool...\\nis by far the best attachment available for the Rail X and any other standard excavator. This full 000 degree rotating jaw bucket has the ability to make efficient detailed adjustments in many directions standing still or on the move.\\nWhich makes clean up between rails, removing slides, fallen trees, grade and clean ditches, remove and replacing rail ties, measure, spread and grade ballast operations done accurate, quick and effectively.\\nFast - Efficient - Flexable...\\n\"Barely describe the benefits and capabilities of this attachment... This efficient tool is so versatile, one bucket can replace several other attachments.\"\\n\"This One Tool is a must have attachment... for any equipment that uses a bucket \" So when you want to get a gripp Get the Roto GrippTM !\\n\"Powerful Features\"\\n000 Degree Rotation\\nDanzco High Pressure Swivel\\nHeavy Duty Worm Drive Gear Bearing\\nHigh Torque Motor\\nHigh Tensile Steel Construction\\n0000 Induction Hardened Pin\\nCase Hardened Bushings\\n\"Model Details\"\\nMachine Size\\nCubic Yards\\n000RB00\\n00,000-00,000K\\n00”\\nAdvanced Rail Concepts, LLC\\n00000 Broadway Ave SE\\nSnohomish, WA 00000-0000\\nCopyright 0000 by Advanced Rail Concepts |Privacy Statement|Terms Of Use'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
